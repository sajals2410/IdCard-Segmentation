{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b6c4e0-3153-4fba-87fe-8f8946805b2b",
   "metadata": {},
   "source": [
    "# ID Card Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b8863-db90-46ae-bd57-6155d4c6463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import wget\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce7bce-d07b-41e6-b5ed-f669f637f4b4",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be4b69-c5ab-4bb0-8f83-51a3a0a08b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2e43d-5263-41ba-8c96-53d651952df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    return warped\n",
    "\n",
    "\n",
    "def findLargestCountours(cntList, cntWidths):\n",
    "    newCntList = []\n",
    "    newCntWidths = []\n",
    "\n",
    "    first_largest_cnt_pos = cntWidths.index(max(cntWidths))\n",
    "\n",
    "    newCntList.append(cntList[first_largest_cnt_pos])\n",
    "    newCntWidths.append(cntWidths[first_largest_cnt_pos])\n",
    "\n",
    "    cntList.pop(first_largest_cnt_pos)\n",
    "    cntWidths.pop(first_largest_cnt_pos)\n",
    "\n",
    "    seccond_largest_cnt_pos = cntWidths.index(max(cntWidths))\n",
    "\n",
    "    newCntList.append(cntList[seccond_largest_cnt_pos])\n",
    "    newCntWidths.append(cntWidths[seccond_largest_cnt_pos])\n",
    "\n",
    "    cntList.pop(seccond_largest_cnt_pos)\n",
    "    cntWidths.pop(seccond_largest_cnt_pos)\n",
    "    return newCntList, newCntWidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17320a-bccb-477f-a780-b6bac801c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_object(mask, image):\n",
    "    gray = mask\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    edged = cv2.Canny(np.uint8(gray), 30, 400)\n",
    "    countours, _ = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    cnts = sorted(countours, key=cv2.contourArea, reverse=True)\n",
    "    screenCntList = []\n",
    "    scrWidths = []\n",
    "    for cnt in cnts:\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "        screenCnt = approx\n",
    "\n",
    "        if (len(screenCnt) == 4):\n",
    "            (X, Y, W, H) = cv2.boundingRect(cnt)\n",
    "            screenCntList.append(screenCnt)\n",
    "            scrWidths.append(W)\n",
    "\n",
    "    if len(scrWidths) != 2:\n",
    "        print('ID Card not found.')\n",
    "        return None\n",
    "    else:\n",
    "        screenCntList, scrWidths = findLargestCountours(screenCntList, scrWidths)\n",
    "\n",
    "        if not len(screenCntList) >= 2:  # there is no rectangle found\n",
    "            return None\n",
    "        elif scrWidths[0] != scrWidths[1]:  # mismatch in rect\n",
    "            return None\n",
    "\n",
    "        pts = screenCntList[0].reshape(4, 2)\n",
    "        warped = four_point_transform(image, pts)\n",
    "        return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f283ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true), -1) + K.sum(K.square(y_pred), -1) + smooth)\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou_loss(true, pred):\n",
    "    intersection = true * pred\n",
    "    notTrue = 1 - true\n",
    "    union = true + (notTrue * pred)\n",
    "    return K.sum(intersection)/K.sum(union)\n",
    "\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "\n",
    "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
    "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
    "    gradient.\n",
    "\n",
    "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "    @author: wassname\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e537d2f-fc9c-4d67-a67f-a2be3c8a5a76",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_links = [\n",
    "    'ftp://smartengines.com/midv-500/dataset/12_deu_drvlic_new.zip',\n",
    "    'ftp://smartengines.com/midv-500/dataset/13_deu_drvlic_old.zip',\n",
    "    'ftp://smartengines.com/midv-500/dataset/14_deu_id_new.zip',\n",
    "    'ftp://smartengines.com/midv-500/dataset/15_deu_id_old.zip',\n",
    "    'ftp://smartengines.com/midv-500/dataset/16_deu_passport_new.zip',\n",
    "    'ftp://smartengines.com/midv-500/dataset/17_deu_passport_old.zip']\n",
    "\n",
    "'''\n",
    "download_links = ['ftp://smartengines.com/midv-500/dataset/01_alb_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/02_aut_drvlic_new.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/03_aut_id_old.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/04_aut_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/05_aze_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/06_bra_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/07_chl_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/08_chn_homereturn.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/09_chn_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/10_cze_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/11_cze_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/12_deu_drvlic_new.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/13_deu_drvlic_old.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/14_deu_id_new.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/15_deu_id_old.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/16_deu_passport_new.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/17_deu_passport_old.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/18_dza_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/19_esp_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/20_esp_id_new.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/21_esp_id_old.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/22_est_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/23_fin_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/24_fin_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/25_grc_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/26_hrv_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/27_hrv_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/28_hun_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/29_irn_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/30_ita_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/31_jpn_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/32_lva_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/33_mac_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/34_mda_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/35_nor_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/36_pol_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/37_prt_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/38_rou_drvlic.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/39_rus_internalpassport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/40_srb_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/41_srb_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/42_svk_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/43_tur_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/44_ukr_id.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/45_ukr_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/46_ury_passport.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/47_usa_bordercrossing.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/48_usa_passportcard.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/49_usa_ssn82.zip',\n",
    "                  'ftp://smartengines.com/midv-500/dataset/50_xpo_id.zip']\n",
    "'''\n",
    "\n",
    "PATH_OFFSET = 40\n",
    "TARGET_PATH = 'dataset/data/'\n",
    "\n",
    "TEMP_PATH = 'dataset/temp/'\n",
    "TEMP_IMAGE_PATH = TEMP_PATH + 'image/'\n",
    "TEMP_MASK_PATH = TEMP_PATH + 'mask/'\n",
    "\n",
    "DATA_PATH = 'dataset/train/'\n",
    "\n",
    "SEED = 230\n",
    "\n",
    "\n",
    "def read_image(img, label):\n",
    "    image = cv2.imread(img)\n",
    "    mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "    quad = json.load(open(label, 'r'))\n",
    "    coords = np.array(quad['quad'], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, coords.reshape(-1, 4, 2), color=(255, 255, 255))\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.resize(mask, (mask.shape[1] // 2, mask.shape[0] // 2))\n",
    "    image = cv2.resize(image, (image.shape[1] // 2, image.shape[0] // 2))\n",
    "    mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def download_and_unzip():\n",
    "    if os.path.exists(TEMP_PATH):\n",
    "        shutil.rmtree(TEMP_PATH, ignore_errors=True)\n",
    "\n",
    "    os.mkdir(TEMP_PATH)\n",
    "    os.mkdir(TEMP_IMAGE_PATH)\n",
    "    os.mkdir(TEMP_MASK_PATH)\n",
    "\n",
    "    file_idx = 1\n",
    "\n",
    "    for link in download_links:\n",
    "        filename = link[PATH_OFFSET:]\n",
    "        full_filename = TARGET_PATH + filename\n",
    "        directory_name = TARGET_PATH + link[PATH_OFFSET:-4]\n",
    "\n",
    "        print('Collect and prepare datasets...')\n",
    "\n",
    "        print('Dataset available... ', directory_name)\n",
    "        if not os.path.exists(directory_name):\n",
    "            if not os.path.isfile(full_filename):\n",
    "                print ('Downloading:', link)\n",
    "                wget.download(link, TARGET_PATH)\n",
    "\n",
    "            with zipfile.ZipFile(full_filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall(TARGET_PATH)\n",
    "\n",
    "        print('Prepare dataset... ', directory_name)\n",
    "        img_dir_path = './' + directory_name + '/images/'\n",
    "        gt_dir_path = './' + directory_name + '/ground_truth/'\n",
    "\n",
    "        if os.path.isfile(img_dir_path + filename + '.tif'):\n",
    "            os.remove(img_dir_path + filename.replace('.zip', '.tif'))\n",
    "        if os.path.isfile(gt_dir_path + filename + '.json'):\n",
    "            os.remove(gt_dir_path + filename.replace('.zip', '.json'))\n",
    "\n",
    "        for images, ground_truth in zip(sorted(os.listdir(img_dir_path)), sorted(os.listdir(gt_dir_path))):\n",
    "            img_list = sorted(glob(img_dir_path + images + '/*.tif'))\n",
    "            label_list = sorted(glob(gt_dir_path + ground_truth + '/*.json'))\n",
    "            for img, label in zip(img_list, label_list):\n",
    "                image, mask = read_image(img, label)\n",
    "                cv2.imwrite(TEMP_IMAGE_PATH + 'image' + str(file_idx) + '.png', image)\n",
    "                cv2.imwrite(TEMP_MASK_PATH + 'image' + str(file_idx) + '.png', mask)\n",
    "\n",
    "                file_idx += 1\n",
    "\n",
    "        print('----------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "def train_validation_split():\n",
    "    if os.path.exists(DATA_PATH):\n",
    "        shutil.rmtree(DATA_PATH, ignore_errors=True)\n",
    "\n",
    "    folders = ['train_frames/image', 'train_masks/image', 'val_frames/image', 'val_masks/image', 'test_frames/image',\n",
    "               'test_masks/image']\n",
    "\n",
    "    for folder in folders:\n",
    "        os.makedirs(DATA_PATH + folder)\n",
    "\n",
    "    all_frames = os.listdir(TEMP_IMAGE_PATH)\n",
    "    all_masks = os.listdir(TEMP_MASK_PATH)\n",
    "\n",
    "    all_frames.sort(key=lambda var: [int(x) if x.isdigit() else x\n",
    "                                     for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "    all_masks.sort(key=lambda var: [int(x) if x.isdigit() else x\n",
    "                                    for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "    random.seed(SEED)\n",
    "    random.shuffle(all_frames)\n",
    "\n",
    "    train_split = int(0.7 * len(all_frames))\n",
    "    val_split = int(0.9 * len(all_frames))\n",
    "\n",
    "    train_frames = all_frames[:train_split]\n",
    "    val_frames = all_frames[train_split:val_split]\n",
    "    test_frames = all_frames[val_split:]\n",
    "\n",
    "    train_masks = [f for f in all_masks if f in train_frames]\n",
    "    val_masks = [f for f in all_masks if f in val_frames]\n",
    "    test_masks = [f for f in all_masks if f in test_frames]\n",
    "\n",
    "    def add_frames(dir_name, image):\n",
    "        img = Image.open(TEMP_IMAGE_PATH + image)\n",
    "        img.save(DATA_PATH + '/{}'.format(dir_name) + '/' + image)\n",
    "\n",
    "    def add_masks(dir_name, image):\n",
    "        img = Image.open(TEMP_MASK_PATH + image)\n",
    "        img.save(DATA_PATH + '/{}'.format(dir_name) + '/' + image)\n",
    "\n",
    "    frame_folders = [(train_frames, 'train_frames/image'), (val_frames, 'val_frames/image'),\n",
    "                     (test_frames, 'test_frames/image')]\n",
    "    mask_folders = [(train_masks, 'train_masks/image'), (val_masks, 'val_masks/image'),\n",
    "                    (test_masks, 'test_masks/image')]\n",
    "\n",
    "    print('Split images into train, test and validation...')\n",
    "\n",
    "    for folder in frame_folders:\n",
    "        array = folder[0]\n",
    "        name = [folder[1]] * len(array)\n",
    "        list(map(add_frames, name, array))\n",
    "\n",
    "    for folder in mask_folders:\n",
    "        array = folder[0]\n",
    "        name = [folder[1]] * len(array)\n",
    "        list(map(add_masks, name, array))\n",
    "\n",
    "\n",
    "download_and_unzip()\n",
    "train_validation_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5e99c-b6b1-4339-89bf-9e4808b7724f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "def UNET(input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79588586-4fae-419f-b285-e2d04f4c901f",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea11bb-ae75-4ac1-ba95-41801f0f4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "import models\n",
    "from utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b1b4e-80cd-4127-907d-02002b7e1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_TRAINING_IMAGES = len(os.listdir('dataset/train/train_frames/image'))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir('dataset/train/val_frames/image'))\n",
    "\n",
    "NO_OF_EPOCHS = 500\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "SEED = 230\n",
    "rn.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae6191-38a4-49aa-b419-4e578922870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_image_generator = train_datagen.flow_from_directory('./dataset/train/train_frames',\n",
    "                                                          target_size=IMAGE_SIZE,\n",
    "                                                          class_mode=None,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          color_mode='grayscale',\n",
    "                                                          seed=SEED)\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory('dataset/train/train_masks',\n",
    "                                                         target_size=IMAGE_SIZE,\n",
    "                                                         class_mode=None,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         seed=SEED)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_image_generator = val_datagen.flow_from_directory('dataset/train/val_frames',\n",
    "                                                      target_size=IMAGE_SIZE,\n",
    "                                                      class_mode=None,\n",
    "                                                      batch_size=BATCH_SIZE,\n",
    "                                                      color_mode='grayscale',\n",
    "                                                      seed=SEED)\n",
    "\n",
    "val_mask_generator = val_datagen.flow_from_directory('dataset/train/val_masks',\n",
    "                                                     target_size=IMAGE_SIZE,\n",
    "                                                     class_mode=None,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     color_mode='grayscale',\n",
    "                                                     seed=SEED)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "model = models.UNET(input_size=(256, 256, 1))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy', metrics.mean_iou])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True, save_weights_only=False,\n",
    "                             monitor='val_mean_iou', mode='max')\n",
    "earlystopping = EarlyStopping(patience=10, verbose=1, monitor='val_mean_iou', mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.2, patience=3, verbose=1, min_delta=0.000001,\n",
    "                              monitor='val_mean_iou', mode='max')\n",
    "tensorboard = TensorBoard(log_dir='./logs/' + time.strftime(\"%Y%m%d_%H%M%S\"), histogram_freq=0,\n",
    "                          write_graph=True, write_images=True)\n",
    "\n",
    "model.fit_generator(train_generator, epochs=NO_OF_EPOCHS,\n",
    "                    steps_per_epoch=(NO_OF_TRAINING_IMAGES // BATCH_SIZE),\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=(NO_OF_VAL_IMAGES // BATCH_SIZE),\n",
    "                    callbacks=[checkpoint, earlystopping, reduce_lr, tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e214a8-a148-493a-b397-af2a72ed638f",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27318642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n",
    "from matplotlib import gridspec\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from utils import image\n",
    "from utils import metrics\n",
    "\n",
    "IMPORT_FILES = \"./test/*.png\"\n",
    "MODEL_FILE = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8742d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img / 255.0\n",
    "    height, width = img.shape[:2]\n",
    "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(1, 256, 256, 1)\n",
    "    return img, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = []\n",
    "for file_path in glob.glob(IMPORT_FILES):\n",
    "    raw = cv2.imread(file_path)\n",
    "    raw = cv2.cvtColor(raw, cv2.COLOR_BGR2RGB)\n",
    "    img, h, w = load_data(file_path)\n",
    "    images_dict.append({\"raw\": raw, \"data\": img, \"height\": h, \"width\": w}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(1, len(images_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e831af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "for n in range(len(images_dict)):\n",
    "    ax = fig.add_subplot(gs[n])\n",
    "    ax.imshow(images_dict[n][\"raw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_FILE, custom_objects={'mean_iou': metrics.mean_iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b222b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(images_dict)):\n",
    "    data = images_dict[n]    \n",
    "    data[\"prediction\"] = model.predict(data[\"data\"])[0]\n",
    "    img = cv2.resize(data[\"prediction\"], (data[\"width\"], data[\"height\"])) \n",
    "    img = img_as_ubyte(img)    \n",
    "    data[\"mask\"] = cv2.threshold(np.array(img), 200, 255, cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "for n in range(len(images_dict)):\n",
    "    ax = fig.add_subplot(gs[n])\n",
    "    data = images_dict[n]\n",
    "    ax.imshow(data[\"mask\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e130a",
   "metadata": {},
   "source": [
    "## RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "for n in range(len(images_dict)):\n",
    "    ax = fig.add_subplot(gs[n])\n",
    "    data = images_dict[n]    \n",
    "    res = image.convert_object(data[\"mask\"], data[\"raw\"])\n",
    "    if res is None:\n",
    "        res = np.ones((1,1,3), np.uint8)\n",
    "    ax.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9f061-c892-44fb-b82d-6ab98aa23598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
